+++
date = 2017-12-01
title = "Missing data analysis"
subtitle = "Missing data analysis when you are *happy* that your data is missing at random"

+++

## Motivation

Data, data, data... you hear about it all the time, perhaps in the news, chatting with friends, or maybe at your place of work. But how much data is there, how do we collect it, and what happens when data collection goes wrong?

There is so much data in the world that it is hard to imagine how it all gets stored. For example, Google was said to process 20 petabytes of data per day, and the IDC predicts that there will be 175 zettabytes of data by 2025.
*"Wait a sec, what was that, petabytes and zettabytes?"*
My head is hurting already. A zettabyte is 1000 exabytes, an exabyte is 1000 petabytes, a petabyte is 1000 terabytes, and a terabyte is 1000 gigabytes. Now, considering that an iPhone can hold 256 gigabytes, then holding a zettabyte in your hand is the equivalent of holding approximately 4 trillion of these iPhones in your hand... *"woah, this is heavy!"* In other words, if you stacked a zettabyte's worth of data on CD-ROMs then you would be able to reach the moon and a quarter beyond it and then be able to do it again another 999 times until which point you ran out of data.  

This abundance of data can be collected in any number of ways. For example, information on patients who have been tested for the coronavirus (the devastating global pandemic of 2020) is usually collected by healthcare professionals and stored on a government database (if the country has this electronic system in place). Depending on how many patients are tested, and how much information was collected on each patient, the data that is stored could be as small as 1 gigabyte or as large as a terabyte, maybe even more. However, having more data does not necessary guarantee that you have more information. For example, if you were to routinely collect data on your health (e.g. blood pressure, heart rate, height, weight, etc.) for 30 days you would probably have a record for each of those health factors on each of those days. But when it comes to big data that is collected on multiple patients at multiple time points, such as coronavirus cases or cancer cases, then the quality of the data (i.e. the completeness of the records) can start to dwindle. There as many reasons for the dwindling of the records as there are zettabytes in the world.

*"Okay, so big data is not necessarily always a good thing because there can be an incompleteness of records. But, what can we do about it?"*

This is where missing data analysis can be an extremely useful tool.

## Clarification



## Multiple Imputation


(Constantly updated, the author is lethargic...)
